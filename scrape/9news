#!/usr/bin/env python3

from datetime import datetime

from bs4 import BeautifulSoup
import pytz
import requests

from utils import update_feed


response = requests.get('https://www.9news.com/local')
html = BeautifulSoup(response.text, 'html.parser')

json_feed = {
    'version': 'https://jsonfeed.org/version/1.1',
    'title': '9News: Local',
    'home_page_url': 'https://sreynen.github.io/denver-news/',
    'feed_url': 'https://sreynen.github.io/denver-news/9news.json',
    'items': []
}

now = pytz.utc.localize(datetime.now()).isoformat()

unique_items = {}

def item_from_link(link, now):
    url = link['href']
    if url[0] == '/':
        url = 'https://www.9news.com' + url
    return {
        'id': url,
        'url': url,
        'title': ' '.join(link.stripped_strings),
        'date_published': now,
        'date_modified': now
    }

for link in html.select('div.story__meta a.story__link'):
    unique_items[link['href']] = item_from_link(link, now)

for link in html.select('li.headline-list__item a.headline-list__title'):
    unique_items[link['href']] = item_from_link(link, now)

for link in html.select('li.carousel__item a.carousel__description'):
    unique_items[link['href']] = item_from_link(link, now)

for link in html.select('li.story-list__item a.story-list__title-link'):
    unique_items[link['href']] = item_from_link(link, now)

json_feed['items'] = list(unique_items.values())

update_feed('./json/9news.json', json_feed)
